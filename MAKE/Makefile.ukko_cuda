# Makefile for the ukko Cluster at UH, using nvidia GPUs
#
# Recommended setup:
# * Compile on an interactive node with the below modules;
#   See the It4Science wiki or the Vorna guide
#   https://github.com/fmihpc/analysator/wiki/Vorna-guide
#   for the current best practice.
# * Use mpirun to run, with the following (rather long) command line:
#   mpirun -mca pml ucx --mca btl ^vader,tcp,openib -x UCX_NET_DEVICES=mlx5_0:1 -x UCX_TLS=rc,sm -x UCX_IB_ADDR_TYPE=ib_global $executable --run_config $configfile
#
# As of January 2025, CUDA with GCC 13 is broken, so we fall back to GCC 11.
#
# module load GCC/11.2.0
# module load OpenMPI/4.1.1-GCC-11.2.0
# module load PMIx/4.1.0-GCCcore-11.2.0
# module load PAPI/6.0.0.1-GCCcore-11.2.0
# module load CUDA
# module load Boost/1.55.0-GCC-11.2.0
#
# Oneliner for command line:
# module purge; ml GCC/11.2.0; ml OpenMPI/4.1.1-GCC-11.2.0; ml PMIx/4.1.0-GCCcore-11.2.0; ml PAPI/6.0.0.1-GCCcore-11.2.0; ml CUDA; ml Boost/1.55.0-GCC-11.2.0

#======== Vectorization ==========
#Set vector backend type for vlasov solvers, sets precision and length.
#Options:
VECTORCLASS = VEC_FALLBACK_GENERIC

#===== Vector Lengths ====
# Default for VEC_FALLBACK_GENERIC is WID=4, VECL=8
# NOTE: A bug currently results in garbage data already on cell init if VECL is not equal to WID2
#WID=8
#VECL=64
WID=4
VECL=16

#======= Compiler and compilation flags =========
# NOTES on compiler flags:
# CXXFLAGS is for compiler flags, they are always used
# MATHFLAGS are for special math etc. flags, these are only applied on solver functions
# LDFLAGS flags for linker

#-DNO_WRITE_AT_ALL:  Define to disable write at all to
#                    avoid memleak (much slower IO)
#-DMPICH_IGNORE_CXX_SEEK: Ignores some multiple definition
#                         errors that come up when using
#                         mpi.h in c++ on Cray
#
# CXXFLAGS = -DMPICH_IGNORE_CXX_SEEK

USE_CUDA=1

FLAGS =

#-ggdb not available on nvcc
#-G (device debug) overrides --generate-line-info -line-info but also requires more device-side resources to run
# use "-Xptxas -v" for verbose output of ptx compilation
# --cudart shared used for Kostis' mempool_ts
CXXFLAGS = -g -O3 -x cu -std=c++20 --extended-lambda --expt-relaxed-constexpr -gencode arch=compute_80,code=sm_80 --cudart shared --generate-line-info -line-info -Xcompiler="-fopenmp" -Xcompiler="-fpermissive" -maxrregcount 24 -Wno-deprecated-declarations
testpackage: CXXFLAGS = -g -O2 -x cu -std=c++20 --extended-lambda --expt-relaxed-constexpr -gencode arch=compute_80,code=sm_80 --cudart shared --generate-line-info -line-info -Xcompiler="-fopenmp" -Xcompiler="-fpermissive" -maxrregcount 24 -Wno-deprecated-declarations

# Tell mpic++ to use nvcc for all compiling
CMP = OMPI_CXX='nvcc' OMPI_CXXFLAGS='' mpic++

# Now tell also the linker to use nvcc. Contents of these were retrieved with "mpic++ --showme:link".
# Use this same linker command also for building and linking phiprof.  ## The line below indeed uses OMPI_CXX, not OMPI_LD
LNK = OMPI_CXX='nvcc' OMPI_CXXFLAGS='-arch=sm_80' OMPI_LIBS='-L/appl/easybuild/opt/hwloc/2.5.0-GCCcore-11.2.0/lib -L/appl/easybuild/opt/libevent/2.1.12-GCCcore-11.2.0/lib64' OMPI_LDFLAGS=' -Xlinker=-rpath=/appl/easybuild/opt/hwloc/2.5.0-GCCcore-11.2.0/lib -Xlinker=-rpath=/appl/easybuild/opt/libevent/2.1.12-GCCcore-11.2.0/lib64 -Xlinker=-rpath=/appl/easybuild/opt/OpenMPI/4.1.1-GCC-11.2.0/lib -Xlinker=--enable-new-dtags -L/appl/easybuild/opt/OpenMPI/4.1.1-GCC-11.2.0/lib -lmpi' mpic++

MATHFLAGS = --use_fast_math
# nvcc fast_math does not assume only finite math
testpackage: MATHFLAGS = --prec-sqrt=true --prec-div=true --ftz=false --fmad=false

LDFLAGS = -lrt -lgfortran -std=c++20 -lgomp
LIB_MPI = -lgomp -lmpi

#======== PAPI ==========
#Add PAPI_MEM define to use papi to report memory consumption?
CXXFLAGS += -DPAPI_MEM
testpackage: CXXFLAGS += -DPAPI_MEM

#======== Allocator =========
#Use jemalloc instead of system malloc to reduce memory fragmentation? https://github.com/jemalloc/jemalloc
#Configure jemalloc with  --with-jemalloc-prefix=je_ when installing it
#NOTE: jemalloc not supported with GPUs
#CXXFLAGS += -DUSE_JEMALLOC -DJEMALLOC_NO_DEMANGLE
#testpackage: CXXFLAGS += -DUSE_JEMALLOC -DJEMALLOC_NO_DEMANGLE

# BOOST_VERSION = current trilinos version
# ZOLTAN_VERSION = current trilinos verson
#
#======== Libraries ===========

MPT_BRAND = OpenMPI
MPT_VERSION = 4.1.1
CC_BRAND = nvcc2
CC_BRAND_VERSION = 12.4

LIBRARY_PREFIX = /proj/group/spacephysics/libraries

#compiled libraries mostly in modules
LIB_PROFILE = -L$(LIBRARY_PREFIX)/$(CC_BRAND)/$(CC_BRAND_VERSION)/$(MPT_BRAND)/$(MPT_VERSION)/phiprof/lib -lphiprof -Xlinker=-rpath=$(LIBRARY_PREFIX)/$(CC_BRAND)/$(CC_BRAND_VERSION)/$(MPT_BRAND)/$(MPT_VERSION)/phiprof/lib
INC_PROFILE = -I $(LIBRARY_PREFIX)/$(CC_BRAND)/$(CC_BRAND_VERSION)/$(MPT_BRAND)/$(MPT_VERSION)/phiprof/include

LIB_VLSV = -L$(LIBRARY_PREFIX)/$(CC_BRAND)/$(CC_BRAND_VERSION)/$(MPT_BRAND)/$(MPT_VERSION)/vlsv -lvlsv -Xlinker=-rpath=$(LIBRARY_PREFIX)/$(CC_BRAND)/$(CC_BRAND_VERSION)/$(MPT_BRAND)/$(MPT_VERSION)/vlsv
INC_VLSV = -I$(LIBRARY_PREFIX)/$(CC_BRAND)/$(CC_BRAND_VERSION)/$(MPT_BRAND)/$(MPT_VERSION)/vlsv

# Boost from system module
LIB_BOOST = -lboost_program_options

LIB_ZOLTAN = -L$(LIBRARY_PREFIX)/$(CC_BRAND)/$(CC_BRAND_VERSION)/$(MPT_BRAND)/$(MPT_VERSION)/zoltan/lib -lzoltan -Xlinker=-rpath=$(LIBRARY_PREFIX)/$(CC_BRAND)/$(CC_BRAND_VERSION)/$(MPT_BRAND)/$(MPT_VERSION)/zoltan/lib
INC_ZOLTAN = -isystem $(LIBRARY_PREFIX)/$(CC_BRAND)/$(CC_BRAND_VERSION)/$(MPT_BRAND)/$(MPT_VERSION)/zoltan/include

LIB_PAPI = -lpapi
